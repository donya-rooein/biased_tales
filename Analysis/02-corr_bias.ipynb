{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update to the new data format, which simplifies things!\n",
    "# TODO: update this from notebook to semi-interactive script\n",
    "\n",
    "import nltk # type: ignore\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer # type: ignore\n",
    "import csv\n",
    "import re\n",
    " \n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def story_text_cleaned(text):\n",
    "    if text:  # Check if the text is not None or NaN\n",
    "        match = re.search(r\"---\\s*(.*?)\\s*---\", text, re.S)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return text  # Return the original text if no match is found\n",
    "\n",
    "def lemmatize_word(word: str) -> str:\n",
    "    word = word.replace(\"bravery\", \"brave\").replace(\"haired\", \"hair\")\n",
    "    return wnl.lemmatize(word)\n",
    "\n",
    "def lemmatize_text(text: str) -> str:\n",
    "    text = nltk.word_tokenize(text.lower())\n",
    "    return \" \".join([lemmatize_word(word) for word in text])\n",
    "\n",
    "def process_data(data):\n",
    "    attribute_words = {x for line in data for x in lemmatize_text(line[\"protagonist_attributes\"]).split(\" \") if x} | {\"boy\", \"son\", \"child\", \"girl\", \"daughter\"}\n",
    "    for line in data:\n",
    "        line[\"story_text_cleaned\"] = story_text_cleaned(line[\"story_text\"])\n",
    "        line[\"story_text_lemmas\"] = lemmatize_text(line[\"story_text_cleaned\"])\n",
    "        line[\"story_text_lemmas\"] = \" \".join([x for x in line[\"story_text_lemmas\"].split(\" \") if x not in attribute_words])\n",
    "\n",
    "        if \"protagonist_attributes_list\" in line:\n",
    "            words = line[\"protagonist_attributes_list\"].strip(\"[]'\").lower().split(\"', '\")\n",
    "            words = [lemmatize_word(word) for word in words]\n",
    "            line[\"protagonist_attributes\"] = \" \".join(words)\n",
    "        else:\n",
    "            line[\"protagonist_attributes\"] = lemmatize_text(line[\"protagonist_attributes\"])\n",
    "\n",
    "    for line in data:\n",
    "        if \"race_of_parent\" in line:\n",
    "            line[\"race_of_parent\"] = line[\"race_of_parent\"].replace(\"African-American\", \"African-Amer.\").replace(\"European-American\", \"European-Amer.\")\n",
    "            \n",
    "        if \"nationality_parent\" not in line:\n",
    "            continue\n",
    "        x = line[\"nationality_parent\"]\n",
    "        line[\"nationality_parent_group\"] = (\n",
    "            \"North American\" if x in {\"American\", \"Canadian\"} else\n",
    "            \"South American\" if x in {\"Mexican\", \"Brazilian\"} else\n",
    "            \"European\" if x in {\"British\", \"German\", \"French\", \"Italian\", \"Russian\"} else\n",
    "            \"Middle Eastern\" if x in {\"Armenian\", \"Afghan\", \"Azerbaijani\", \"Egyptian\", \"Iranian\", \"Iraqi\"} else\n",
    "            \"Africa\" if x in {\"Ethiopian\", \"Kenyan\", \"Malian\", \"Nigerian\", \"South African\", \"Sudanese\"} else\n",
    "            \"Asia\" if x in {\"Chinese\", \"Filipino\", \"Indian\", \"Indonesian\", \"Japanese\", \"Sri Lankan\", \"Tajik\", \"Thai\", \"Vietnamese\"} else\n",
    "            \"Other\"\n",
    "        )\n",
    "        line[\"nationality_parent_developed\"] = (\n",
    "            \"Developed\" if x in {\"American\", \"British\", \"Canadian\", \"French\", \"German\", \"Italian\", \"Japanese\", \"Russian\"} else\n",
    "            \"Developing\" if x in {\"Afghan\", \"Armenian\", \"Azerbaijani\", \"Brazilian\", \"Chinese\", \"Egyptian\", \"Ethiopian\", \"Filipino\", \"Indian\", \"Indonesian\", \"Iranian\", \"Iraqi\", \"Kenyan\", \"Malian\", \"Mexican\", \"Nigerian\", \"South African\", \"Sri Lankan\", \"Sudanese\", \"Tajik\", \"Thai\", \"Vietnamese\"} else\n",
    "            \"Other\"\n",
    "        )\n",
    "    return data\n",
    "\n",
    "data = {\n",
    "    \"exp2\": process_data(list(csv.DictReader(open('data/exp2-all_raw_data.csv', 'r')))),\n",
    "    # race_of_parent\n",
    "    \"exp3\": process_data(list(csv.DictReader(open('data/exp3-gpt4-categorized.csv', 'r')))),\n",
    "    # religion_of_parent\n",
    "    \"exp4\": process_data(list(csv.DictReader(open('data/exp4-gpt4-categorized.csv', 'r')))),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "def corr_bias_table(in_variable: str=\"story_text_lemmas\", out_variable: str=\"gender_of_child\", examples_per_class: int = 6):\n",
    "    if out_variable == \"race_of_parent\":\n",
    "        data_local = data[\"exp3\"]\n",
    "    elif out_variable == \"religion_of_parent\":\n",
    "        data_local = data[\"exp4\"]\n",
    "    else:\n",
    "        data_local = data[\"exp2\"]\n",
    "\n",
    "    vectorizer = sklearn.feature_extraction.text.CountVectorizer(\n",
    "        max_features=100,\n",
    "        min_df=5,\n",
    "        # these stop words include he/she/they/etc\n",
    "        stop_words='english',\n",
    "    )\n",
    "    data_x = np.array(vectorizer.fit_transform([d[in_variable] for d in data_local]).toarray() > 0, dtype=int)\n",
    "    # data_x = vectorizer.fit_transform([d['story_text_lemmas'] for d in data_local]).toarray()\n",
    "    data_y = np.array([d[out_variable] for d in data_local])\n",
    "    data_y_targets = sorted(set(data_y))\n",
    "\n",
    "    features_by_class = collections.defaultdict(list)\n",
    "    for feature_i, feature in enumerate(vectorizer.get_feature_names_out()):\n",
    "        data_x_feature = data_x[:, feature_i].flatten()\n",
    "        for target_i, target in enumerate(data_y_targets):\n",
    "            data_y_features = data_y == target\n",
    "            corr = scipy.stats.pearsonr(data_x_feature, data_y_features).correlation\n",
    "            features_by_class[target].append((feature, corr))\n",
    "\n",
    "    with open(f\"generated/corr_{in_variable}_{out_variable}.tex\", \"w\") as f:\n",
    "\n",
    "        print(r\"\\null\\\\[-2.5em]\", file=f)\n",
    "        title = out_variable.replace(\"_\", \" \").title()\n",
    "        print(f\"\\\\multicolumn{{2}}{{l}}{{\\\\bf {title}}} \\\\\\\\\\n\", file=f)\n",
    "        # print(f\"{title} \\\\\\\\\\n\", file=f)\n",
    "        for target, target_v in features_by_class.items():\n",
    "            top_correlating = sorted(target_v, key=lambda x: x[1], reverse=True)[:examples_per_class]\n",
    "            examples = \"\"\n",
    "            for i, (feature, corr) in enumerate(top_correlating):\n",
    "                if i == examples_per_class - 1:\n",
    "                    examples += f\"{{ {{\\\\fontsize{{7}}{{7}}\\\\selectfont {corr:.0%}}} {feature} }}\".replace(\"+-\", \"-\").replace(\"%\", \"\\\\%\") + \" \"\n",
    "                else:\n",
    "                    examples += f\"\\\\makebox[22mm][l]{{ {{\\\\fontsize{{7}}{{7}}\\\\selectfont {corr:.0%}}} {feature} }}\".replace(\"+-\", \"-\").replace(\"%\", \"\\\\%\") + \" \"\n",
    "            \n",
    "            print(\n",
    "                target,\n",
    "                examples,\n",
    "                sep=\" & \",\n",
    "                end=\"\\\\\\\\\\n\",\n",
    "                file=f,\n",
    "            )\n",
    "        print(\"\\\\bottomrule\\\\\\\\\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_bias_table(in_variable=\"story_text_lemmas\", out_variable=\"gender_of_child\")\n",
    "corr_bias_table(in_variable=\"story_text_lemmas\", out_variable=\"nationality_parent_developed\")\n",
    "corr_bias_table(in_variable=\"story_text_lemmas\", out_variable=\"nationality_parent_group\")\n",
    "corr_bias_table(in_variable=\"story_text_lemmas\", out_variable=\"race_of_parent\")\n",
    "corr_bias_table(in_variable=\"story_text_lemmas\", out_variable=\"religion_of_parent\")\n",
    "corr_bias_table(in_variable=\"story_text_lemmas\", out_variable=\"role_of_parent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_bias_table(in_variable=\"protagonist_attributes\", out_variable=\"gender_of_child\")\n",
    "corr_bias_table(in_variable=\"protagonist_attributes\", out_variable=\"nationality_parent_developed\")\n",
    "corr_bias_table(in_variable=\"protagonist_attributes\", out_variable=\"nationality_parent_group\")\n",
    "corr_bias_table(in_variable=\"protagonist_attributes\", out_variable=\"race_of_parent\")\n",
    "corr_bias_table(in_variable=\"protagonist_attributes\", out_variable=\"religion_of_parent\")\n",
    "corr_bias_table(in_variable=\"protagonist_attributes\", out_variable=\"role_of_parent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_bias_table(in_variable=\"protagonist_attributes\", out_variable=\"model\")\n",
    "corr_bias_table(in_variable=\"story_text_lemmas\", out_variable=\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
